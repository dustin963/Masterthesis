{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import datetime\n",
    "import regex\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define Banknames and common versions to replace with \"Bank later\"\n",
    "banknames = [\"C24 Bank\",\"deutsche ing (diba)\",\"bank c24\",\"C24\",\"Deutsche Bank\",\"ING Deutschland\",\"bank ing-diba\",\"ing diba bank\",\"ing-diba bank\",\"ing.diba\",\"bank ing\",\"ingdiba\",\"ing-diba\",\"ing diba\",\"ing bank\",\"ing  diba\",\"n26 bank\",\"bank n26\"\n",
    ",\"N26\",\"Sparda-Bank BW\",\"Sparda-Bank Südwest eG\",\"Volksbank\",\"Commerzbank\",\"dkb bank\",\"bank dkb\",\"DKB\",\"HypoVereinsbank\",\"Hypo\",\"Bunq\",\"bunq bank\"\n",
    ",\"Postbank\",\"PSD Braunschweig\",\"PDF Rhein Ruhr\",\"PSD Karlsruhe\",\"PSD berlin brandenburg\",\"Sparda-Bank Hamburg\",\"Sparda-Bank München\",\"sparda- banken\",\"Sparda-Bank Nürnberg\"\n",
    ",\"Sparkasse Hannover\",\"Volksbank Mittelhessen\",\"volksbank Berlin\",\"Volksbank Hamburg\",\"Sparkasse Köln bonn\",\n",
    "\"sparkasse bank\",\"Sparkasse\",\"sparkasse\",\"Sparda-Bank\",\n",
    "\"spardap\",\"sparda bank\",\"sparda banken\",\"psd bank\",\"psd\",\"targobank\",\"revolut\",\"targo bank\",\"tomorrow\",\"vivid money\",\"vividmoney\",\"vivid-money\",\"vivid\",\"fidor bank\",\"fidor\",\"comdirect\",\"norisbank\",\"santander\",\"noris bank\",\"bunq\",\"Fidorbank\",\"fidor bank\"\n",
    "\" diba \",\"dkb\",\" Diba \",\" diba\",\"(diba)\",\"diba \",\"bank deutschen bank\",\"deutsche Bank\",\"deutschen bank\",\" ING \",\"Bankbank\",\"bank \"]\n",
    "stop_words = stopwords.words(\"german\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the file path\n",
    "\n",
    "import glob\n",
    "datafilepaths = glob.glob(\"MorerecentData/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write Stopwords to excel for appendix\n",
    "stop_words= pd.DataFrame(data=stop_words)\n",
    "with pd.ExcelWriter('stopwords.xlsx') as writer:  \n",
    "    stop_words.to_excel(writer, sheet_name='stopwords',engine=\"xlsxwriter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get customerreview data and create a Dataframe object\n",
    "customerevaluations = pd.DataFrame(columns=['company','date','headline','body','rating'])\n",
    "\n",
    "for files in datafilepaths:\n",
    "    customerevaluation = pd.read_csv(files)\n",
    "    customerevaluations = pd.concat([customerevaluations,customerevaluation],ignore_index=True)\n",
    "\n",
    "customerevaluations[\"date\"] = pd.to_datetime(customerevaluations[\"date\"])\n",
    "customerevaluations.drop_duplicates([\"headline\",\"body\",\"rating\"])\n",
    "customerevaluations[\"length of review\"] = customerevaluations[\"body\"].str.len()\n",
    "\n",
    "#customerevaluations['body'] = customerevaluations['body'].map(lambda x: x.lower())\n",
    "customerevaluations[\"rating\"] = pd.to_numeric(customerevaluations['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate some descriptives\n",
    "summarytable = customerevaluations[[\"rating\",\"company\",\"length of review\"]].groupby([\"company\"]).describe().round(decimals=2)\n",
    "summarybyrating= customerevaluations[[\"rating\",\"length of review\"]].groupby(\"rating\").describe().round(decimals=2)\n",
    "customerevaluations['company'] = customerevaluations['company'].map(lambda x: re.sub('ING Neu2', 'ING', x))\n",
    "customerevaluations['company'] = customerevaluations['company'].map(lambda x: re.sub('ING Neu', 'ING', x))\n",
    "\"\"\"\n",
    "with pd.ExcelWriter('summary tables.xlsx') as writer:  \n",
    "    summarytable.to_excel(writer, sheet_name='summarybybank')\n",
    "    summarybyrating.to_excel(writer, sheet_name='summarybyrating')\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do preprocessing\n",
    "customerevaluations[\"originalbody\"] = customerevaluations['body']\n",
    "customerevaluations['body'] = customerevaluations['body'].map(lambda x: re.sub('&nt', '', x))\n",
    "\n",
    "for word in banknames:\n",
    "    customerevaluations['body'] = customerevaluations['body'].map(lambda x: re.sub(word.lower(),'Bank ', x.lower()))\n",
    "'''\n",
    "for word in stop_words:\n",
    "    #customerevaluations['body'] = customerevaluations['body'].map(lambda x: re.sub(\" \"+word.lower()+\" \", ' ', x))\n",
    "customerevaluations['body'] = customerevaluations['body'].map(lambda x: re.sub('&', '', x))\n",
    "'''\n",
    "customerevaluations['word count'] = customerevaluations['originalbody'].map(lambda x: len(x.strip().split(\" \")))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out spam comments\n",
    "searchfor = ['mois',\"Mois\",\"MOIS\",\"keller\",\"Keller\",\"nahuiiiiiiiiiiii\",\"lakakakakslskdnwkskd\",\"einfach aus prinzip nahuyyyyyyy\",\n",
    "\"nahui\",\"oh yeah nahui\",\"nahuiiiii\",\"kellwerwärter\",\"schnelllgmarceletkevin\",\"83 jahre alt und nach schlaganfall pflegebedürftig\",\"mühlhshabbshsbshyjabvsuabsbsjabasjss\",\"de54100110012621571864\",\"huens\",\"ich kunde der deutschen bank (odenkirchener str. 43, 41236 mönchengladbach)\",\"bernlöhr66538\",\"inshallah\",\"ist ja ekelhaft\",\"drecksverein.geht den bach runter.\",\"leute geht niemals zur Bank der gröste müll\",\"gröster müll der welt.\",\".yyyyyyyyyyyyyyyyyy\",\"oaschlöcher\",\"ja sie wollen, dass ich falle lele\"\n",
    ",\"gelber oasch nahoi\",\"ya kelb ihr seid einfach lächerlich\",\"jetzt werden önkel gefickt najui\",\"alles neider\",\"richtige lipp lipps die gehören gehauen\",\"wiiixxxxxxxerrrr\",\"erika\",\"wenn koi luscht hen koi zeit hen wedder bleed ish en shineesischer saddelit uf erd stertze dud, konschde deene wadde, un wadde, un wadde, un..., bassiert nix. hen ja fielleischt nerffe\",\"xxxxxxxxxcccccxcxc\",\"einfach aus prinzip nahuyyyyyyy\"]\n",
    "customerevaluations = customerevaluations[~customerevaluations.body.str.contains('|'.join(searchfor))]\n",
    "customerevaluations['date'] = customerevaluations['date'].apply(lambda a: pd.to_datetime(a).date()) \n",
    "customerevaluations = customerevaluations[(customerevaluations[\"date\"]< (datetime.date(2022,4,16)))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Substitute Euros\n",
    "customerevaluations['body'] = customerevaluations['body'].map(lambda x: re.sub('\\d{1,},\\d{1,}.€', 'Betrag', x))\n",
    "customerevaluations['body'] = customerevaluations['body'].map(lambda x: re.sub('\\d{1,}.euro', 'Betrag', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptives rating\n",
    "customerevaluations.groupby(\"rating\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set variables for model\n",
    "vectorizer_model = CountVectorizer(stop_words=stop_words)\n",
    "customerevaluations.reset_index(drop=True, inplace=True)\n",
    "sentence_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "embeddings = sentence_model.encode(customerevaluations[\"body\"], show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate model\n",
    "customerevaluations.reset_index(drop=True, inplace=True)\n",
    "topic_model = BERTopic(language=\"german\",calculate_probabilities=False,top_n_words=10,vectorizer_model=vectorizer_model,diversity=0.3,min_topic_size=40)\n",
    "topics, probs = topic_model.fit_transform(customerevaluations[\"body\"],embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get model summary\n",
    "topic_freq = topic_model.get_topic_freq()\n",
    "outliers = topic_freq['Count'][topic_freq['Topic']==-1].iloc[0]\n",
    "print(f\"{outliers} documents have not been classified\")\n",
    "print(f\"The other {topic_freq['Count'].sum() - outliers} documents are {topic_freq['Topic'].shape[0]-1} topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce model to 80\n",
    "topics, probs= topic_model.reduce_topics(customerevaluations[\"body\"], topics, nr_topics=80)\n",
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart(n_words=10,top_n_topics=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerevaluations[\"topic\"] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraxt relevant word for each topic\n",
    "topic_freq = topic_model.get_topic_freq()\n",
    "outliers = topic_freq['Count'][topic_freq['Topic']==-1].iloc[0]\n",
    "topicsAndTopWords = []\n",
    "#for i in range(1,len(topic_freq[\"Topic\"])):\n",
    "for i in range(0,len(topic_freq[\"Topic\"])-1):\n",
    "    t = topic_model.get_topic(i)\n",
    "    words = \"\"\n",
    "\n",
    "    for w in range(0,len(t)-1):\n",
    "        words = words + \"_\" + t[w][0] \n",
    "    topicsAndTopWords.append(words)\n",
    "\n",
    "topicsAndTopWords = pd.DataFrame({\"top words\": topicsAndTopWords})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart(n_words=10,top_n_topics=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with pd.ExcelWriter('15.06NRautoreduced to 100.xlsx') as writer:  \n",
    "    customerevaluations.to_excel(writer, sheet_name='evaluations',engine=\"xlsxwriter\")\n",
    "    topicsAndTopWords.to_excel(writer, sheet_name='topics',engine=\"xlsxwriter\")\n",
    "    #reducedtopicsAndTopWords.to_excel(writer, sheet_name='reduced_topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''#len(reduction[0]) #to reduce topics then before doing everything with reduced model.\n",
    "#topic_model.save(\"Mymodel15topnword\")\n",
    "with pd.ExcelWriter('sentimentanalysis.xlsx') as writer:  \n",
    "    diccdf.to_excel(writer, sheet_name='Wordlist')\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_model.save(\"15.06NRautoreduced to 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_modeltestreload = BERTopic.load(\"15.06NRautoreduced to 50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_modeltestreload.visualize_barchart()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd60cb1fff92a47e9f59bb791192b4be3eac6763708ee8af808223f82f2837ce"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
