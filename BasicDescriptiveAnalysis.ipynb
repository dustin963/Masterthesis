{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import datetime\n",
    "import regex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additionalstopwords = [\"Deutsche\",\"Deutsch\",\"Deutschen\",\"Deutscher\"]\n",
    "stop_words = stopwords.words(\"german\") +additionalstopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "datafilepaths = glob.glob(\"MorerecentData/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerevaluations = pd.DataFrame(columns=['company','date','headline','body','rating'])\n",
    "\n",
    "for files in datafilepaths:\n",
    "    customerevaluation = pd.read_csv(files)\n",
    "    customerevaluations = pd.concat([customerevaluations,customerevaluation],ignore_index=True)\n",
    "\n",
    "customerevaluations[\"date\"] = pd.to_datetime(customerevaluations[\"date\"])\n",
    "customerevaluations.drop_duplicates([\"headline\",\"body\",\"rating\"])\n",
    "customerevaluations[\"length of review\"] = customerevaluations[\"body\"].str.len()\n",
    "customerevaluations['body'] = customerevaluations['body'].map(lambda x: x.lower())\n",
    "customerevaluations[\"rating\"] = pd.to_numeric(customerevaluations['rating'])\n",
    "customerevaluations[\"originalbody\"] = customerevaluations['body']\n",
    "customerevaluations['body'] = customerevaluations['body'].map(lambda x: re.sub('&nt', '', x))\n",
    "banknames = [\"C24 Bank\",\"deutsche ing (diba)\",\"bank c24\",\"C24\",\"Deutsche Bank\",\"ING Deutschland\",\"bank ing-diba\",\"ing diba bank\",\"ing-diba bank\",\"bank ing\",\"ingdiba\",\"ing-diba\",\"ing diba\",\"ing bank\",\"ing  diba\",\"n26 bank\",\"bank n26\"\n",
    ",\"N26\",\"Sparda-Bank BW\",\"Sparda-Bank Südwest eG\",\"Volksbank\",\"Commerzbank\",\"dkb bank\",\"bank dkb\",\"DKB\",\"HypoVereinsbank\",\"Hypo\"\n",
    ",\"Postbank\",\"PSD Braunschweig\",\"PDF Rhein Ruhr\",\"PSD Karlsruhe\",\"PSD berlin brandenburg\",\"Sparda-Bank Hamburg\",\"Sparda-Bank München\",\"sparda- banken\",\"Sparda-Bank Nürnberg\"\n",
    ",\"Sparkasse Hannover\",\"Volksbank Mittelhessen\",\"volksbank Berlin\",\"Volksbank Hamburg\",\"Sparkasse Köln bonn\",\n",
    "\"sparkasse bank\",\"Sparkasse\",\"sparkasse\",\"Sparda-Bank\",\n",
    "\"spardap\",\"sparda bank\",\"sparda banken\",\"psd bank\",\"psd\",\"targobank\",\"revolut\",\"targo bank\",\"tomorrow\",\"vivid money\",\"vividmoney\",\"vivid-money\",\"vivid\",\"fidor bank\",\"fidor\",\"comdirect\",\"norisbank\",\"santander\",\"noris bank\",\"bunq\",\"Fidorbank\",\"fidor bank\"\n",
    "\" diba \",\"dkb\",\"Diba\",\"bank deutschen bank\",\"deutsche Bank\",\"deutschen bank\",\" ING \",\"Bankbank\",\n",
    "\"bank bank\",]\n",
    "for word in banknames:\n",
    "    customerevaluations['body'] = customerevaluations['body'].map(lambda x: re.sub(word.lower(), 'Bank', x))\n",
    "\n",
    "for word in stop_words:\n",
    "    customerevaluations['body'] = customerevaluations['body'].map(lambda x: re.sub(\" \"+word.lower()+\" \", ' ', x))\n",
    "\n",
    "countrynames = [\"Deutschland\",\"Österreich\"]\n",
    "citynames = [\"Berlin\",\"Frankfurt\"]\n",
    "\n",
    "for word in countrynames:\n",
    "    customerevaluations['body'] = customerevaluations['body'].map(lambda x: re.sub(word.lower(), 'Land', x))\n",
    "\n",
    "for word in citynames:\n",
    "    customerevaluations['body'] = customerevaluations['body'].map(lambda x: re.sub(word.lower(), 'Stadt', x))\n",
    "\n",
    "customerevaluations['body'] = customerevaluations['body'].map(lambda x: re.sub('&', '', x))\n",
    "customerevaluations['word count'] = customerevaluations['body'].map(lambda x: len(x.strip().split(\" \")))\n",
    "\n",
    "customerevaluations.groupby([\"company\"]).describe()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mois kommenatre ausfiltern\n",
    "searchfor = ['mois',\"Mois\",\"MOIS\",\"keller\",\"Keller\",\"nahuiiiiiiiiiiii\",\"lakakakakslskdnwkskd\",\"einfach aus prinzip nahuyyyyyyy\",\n",
    "\"nahui\",\"oh yeah nahui\",\"nahuiiiii\",\"kellwerwärter\",\"schnelllgmarceletkevin\",\"83 jahre alt und nach schlaganfall pflegebedürftig\",\"mühlhshabbshsbshyjabvsuabsbsjabasjss\",\"de54100110012621571864\",\"huens\",\"ich kunde der deutschen bank (odenkirchener str. 43, 41236 mönchengladbach)\",\"bernlöhr66538\",\"inshallah\",\"ist ja ekelhaft\",\"drecksverein.geht den bach runter.\",\"leute geht niemals zur Bank der gröste müll\",\"gröster müll der welt.\",\".yyyyyyyyyyyyyyyyyy\",\"oaschlöcher\",\"ja sie wollen, dass ich falle lele\"\n",
    ",\"gelber oasch nahoi\",\"ya kelb ihr seid einfach lächerlich\",\"jetzt werden önkel gefickt najui\",\"alles neider\",\"richtige lipp lipps die gehören gehauen\",\"wiiixxxxxxxerrrr\",\"erika\",\"wenn koi luscht hen koi zeit hen wedder bleed ish en shineesischer saddelit uf erd stertze dud, konschde deene wadde, un wadde, un wadde, un..., bassiert nix. hen ja fielleischt nerffe\",\"xxxxxxxxxcccccxcxc\",\"einfach aus prinzip nahuyyyyyyy\"]\n",
    "customerevaluations = customerevaluations[~customerevaluations.body.str.contains('|'.join(searchfor))]\n",
    "customerevaluations['date'] = customerevaluations['date'].apply(lambda a: pd.to_datetime(a).date()) \n",
    "customerevaluations = customerevaluations[(customerevaluations[\"date\"]< (datetime.date(2022,4,16)))]\n",
    "# still mention in research marketing start?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerevaluations['body'] = customerevaluations['body'].map(lambda x: re.sub('\\d{1,},\\d{1,}.€', 'Betrag', x))\n",
    "customerevaluations['body'] = customerevaluations['body'].map(lambda x: re.sub('\\d{1,}.euro', 'Betrag', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerevaluations.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerevaluations.groupby(\"rating\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customerevaluations = customerevaluations[customerevaluations[\"company\"]== \"Volksbank\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerevaluations.reset_index(drop=True, inplace=True)\n",
    "topic_model = BERTopic(language=\"german\",calculate_probabilities=False,top_n_words=10,nr_topics=\"auto\")\n",
    "topics, probs = topic_model.fit_transform(customerevaluations[\"body\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topics_over_time = topic_model.topics_over_time(customerevaluations[\"body\"], topics, customerevaluations[\"date\"], nr_bins=20)\n",
    "#topics_per_class = topic_model.topics_per_class(customerevaluations[\"body\"],topics,classes= customerevaluations[\"company\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topic_freq = topic_model.get_topic_freq()\n",
    "outliers = topic_freq['Count'][topic_freq['Topic']==-1].iloc[0]\n",
    "print(f\"{outliers} documents have not been classified\")\n",
    "print(f\"The other {topic_freq['Count'].sum() - outliers} documents are {topic_freq['Topic'].shape[0]-1} topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerevaluations[\"topic\"] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = topic_model.get_topic(1)\n",
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topicsAndTopWords = []\n",
    "#for i in range(1,len(topic_freq[\"Topic\"])):\n",
    "for i in range(0,len(topic_freq[\"Topic\"])-1):\n",
    "    t = topic_model.get_topic(i)\n",
    "    words = \"\"\n",
    "\n",
    "    for w in range(0,len(t)-1):\n",
    "        words = words + \"_\" + t[w][0] \n",
    "    topicsAndTopWords.append(words)\n",
    "\n",
    "topicsAndTopWords = pd.DataFrame({\"top words\": topicsAndTopWords})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart(n_words=10,top_n_topics=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_model.update_topics(customerevaluations[\"body\"], topics, n_gram_range=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_topics, new_probs= topic_model.reduce_topics(customerevaluations[\"body\"], topics, nr_topics=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart(n_words=10,top_n_topics=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "customerevaluations[\"reducedtopic\"] = new_topics\n",
    "reducedtopic_freq = topic_model.get_topic_freq()\n",
    "\n",
    "reducedtopicsAndTopWords = []\n",
    "#for i in range(1,len(topic_freq[\"Topic\"])):\n",
    "for i in range(0,len(reducedtopic_freq[\"Topic\"])-1):\n",
    "    t = topic_model.get_topic(i)\n",
    "    words = \"\"\n",
    "\n",
    "    for w in range(0,len(t)-1):\n",
    "        words = words + \"_\" + t[w][0] \n",
    "    reducedtopicsAndTopWords.append(words)\n",
    "\n",
    "reducedtopicsAndTopWords = pd.DataFrame({\"top words\": reducedtopicsAndTopWords})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with pd.ExcelWriter('Model_09_06_2022_size20_nrtopicsauto_reducedto50.xlsx') as writer:  \n",
    "    customerevaluations.to_excel(writer, sheet_name='evaluations',engine=\"xlsxwriter\")\n",
    "    topicsAndTopWords.to_excel(writer, sheet_name='topics',engine=\"xlsxwriter\")\n",
    "    reducedtopicsAndTopWords.to_excel(writer, sheet_name='reduced_topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''#len(reduction[0]) #to reduce topics then before doing everything with reduced model.\n",
    "#topic_model.save(\"Mymodel15topnword\")\n",
    "with pd.ExcelWriter('sentimentanalysis.xlsx') as writer:  \n",
    "    diccdf.to_excel(writer, sheet_name='Wordlist')\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.save(\"Model_09_06_2022_size20_nrtopicsauto_reducedto50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_modeltestreload = BERTopic.load(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_modeltestreload.get_topic(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccfilepaths = glob.glob(\"Dictionaries German language/*\")\n",
    "\n",
    "\n",
    "#sentdict = pd.read_csv(diccfilepaths[0])\n",
    "\n",
    "diccdf1 = pd.read_csv(\n",
    "diccfilepaths[0], sep=\"\\t\",header=None)\n",
    "diccdf2 = pd.read_csv(\n",
    "diccfilepaths[1], sep=\"\\t\",header=None)\n",
    "\n",
    "\n",
    "diccdf = pd.concat([diccdf2,diccdf1],ignore_index=True)\n",
    "    \n",
    "\n",
    "diccdf[0] = diccdf[0].map(lambda x: x[0:x.find(\"|\")]+\",\")\n",
    "diccdf[\"words\"] = (diccdf[0]+diccdf[2]).astype(str)\n",
    "diccdf.fillna(\"nan\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist =[]\n",
    "countsofwords = []\n",
    "iteration = -1\n",
    "for row in diccdf[\"words\"]:\n",
    "    iteration = iteration +1\n",
    "    if row !=\"nan\":\n",
    "        print(row)\n",
    "        wordlist = str(row).split(\",\")\n",
    "        shortcount = []\n",
    "        \n",
    "        for word in wordlist:\n",
    "            \n",
    "            shortcount.append(customerevaluations['body'].str.count(\" \"+word.lower()+\" \").sum())\n",
    "        countsofwords.append(sum(shortcount))\n",
    "    if row ==\"nan\":\n",
    "        singleword = (diccdf[0][iteration])[:-1]\n",
    "        print(\"NAN value    \" +  singleword)\n",
    "        countsofwords.append(customerevaluations['body'].str.count(str(\" \"+singleword.lower()+\" \")).sum())\n",
    "\n",
    "\n",
    "#for word in diccdf[0]:\n",
    "    #countsofwords.append(customerevaluations['body'].str.count(word).sum())\n",
    "\n",
    "diccdf[\"counts\"] = countsofwords\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd60cb1fff92a47e9f59bb791192b4be3eac6763708ee8af808223f82f2837ce"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
